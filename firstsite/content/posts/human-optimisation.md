---
title: "What does human cognition over-optimise for?"
date: 2021-04-20T11:48:18+01:00
draft: true
---

What processes do humans over-optimise for? Does this provide insights for what is required to be an effective agent in new environments?
<!--more-->

Many successful AI algorithms attempt to emulate human thinking. Take reinforcement learning. In reinforcement learning, an agent observes its environment, then takes an action, which then changes its environment. The action aims to help the ahent achieve a specified a goal. If the action taken helps the agent to increase the expectation of achieving the goal, then the agent is rewarded. If the action taken reduces the expectation of achieving the goal, then the agent is punished, and encouraged to take a different action next time.

This parallels human cognition. If a human takes an action that helps the human to survive, dopamine is released by the brain (reward), and the human is encouraged that their action was good. If the action taken reduces the human's chance of survival, pain may be administered (punishment), and the human is therefore dissuaded from taking a similar action in future. This is the primary way that humans learn what actions to take in certain environments.

There are numerous other examples of successful machine learning algorithms taking inspiration from human cognition to achieve high performance on certain tasks (e.g. attention mechanisms, deep neural networks).

I wonder if by a deeper examination of human cognition we can better understand what human brains are strongly optimising for, and hence understand what cognitive processes are deeply required for an intelligent agent (assuming that humans qualify as intelligent agents - which is reasonable, since we are the most intelligent agents we have observed in the universe).

One way to attack this may be to look at which cognitive processes do humans **overemphasise** compared to our best guess of the cognitive processes at a wholly rational agent. I mean **overemphasise** in the sense that humans may think using these processes, even to the point of detriment in understanding our environment.

In [Who's in Charge](https://www.amazon.co.uk/Whos-Charge-Free-Science-Brain/dp/1452655731) by [Michael Gazzaniga](https://psych.ucsb.edu/people/michael-gazzaniga), it is suggested that human brains are 'driven to explain events that make sense out of scattered facts' with causality, even when there are no causal links. [Note to self: this needs much stronger evidence].

Are we over-optimising to find causality? And does this suggest that discovering causal relationships is **essential** for an effective agent?
